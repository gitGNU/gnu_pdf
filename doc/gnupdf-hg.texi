\input texinfo
@comment $Id: $
@comment %**start of header
@setfilename gnupdf-hg.info
@settitle GNU PDF Library Hackers Guide
@comment %**end of header

@comment Avoid the indentation of @example and @smallexample in the
@comment html output.  This doesn't fixes the problem of the
@comment indentation, but it is better than nothing.
@ifhtml
@exampleindent 0
@end ifhtml

@include version.texi

@copying
This is the @cite{GNU PDF Library Hackers Guide},
updated for @strong{libgnupdf} version @strong{@value{VERSION}}.

Copyright @copyright{} 2008, 2011 Free Software Foundation, Inc.

@quotation
Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.3 or
any later version published by the Free Software Foundation; with no
Invariant Sections, no Front-Cover Texts, and no Back-Cover Texts. A
copy of the license is included in the section entitled ``GNU Free
Documentation License''.
@end quotation
@end copying

@titlepage
@sp 6
@center @titlefont{GNU PDF Library Hackers Guide}
@sp 4
@center Updated for version @value{VERSION}.
@sp 5
@page Free Software Foundation
@page
@vskip 0pt plus 1filll
@insertcopying
@end titlepage

@contents

@ifnottex
@node Top
@top GNU PDF Library Hackers Guide

GNU PDF Library Hackers Guide

@insertcopying
@end ifnottex

@menu
* Information for Newcomers::
* The build system::
* Development procedures::
* Tasks management::
* Coding Conventions::
* Writing Documentation::
* Sending Patches::
* Testing the library::
* Updating the AUTHORS file::
@end menu

@node Information for Newcomers
@chapter Information for Newcomers

First of all, many thanks for your interest in collaborate in the development!
Here you will find some useful information to get started. 

@table @strong
@item Getting a copy of the sources

The first step to perform is to get a local copy of the development
sources. Just install a GNU Bazaar client and issue the following
commands.

To get the sources of the GNU PDF Library from the trunk:

@example
$ bzr branch bzr://bzr.savannah.gnu.org/pdf/libgnupdf/trunk
@end example

@item Getting familiar with GNU Bazaar

We are using the GNU Bazaar @footnote{http://bazaar-vcs.org} version
control system. Before to be able to contribute code to this project
you should get familiar to the usage of Bazaar.

The GNU Bazaar User Guide
@footnote{http://doc.bazaar-vcs.org/bzr.dev/en/user-guide/index.html}
is very good. In the Bazaar site (http://www.bazaar-vcs.org)
you will also find useful tips for people coming from other VCSs such
as CVS or subversion.

The ``Bzr For Emacs Devs'' page in the Emacs wiki provides detailed
information on the workflow used in the Emacs project.  Even if we
don't follow that exact workflow, most of the guidelines there apply
in the GNU PDF development.  You can find the document at
@url{http://www.emacswiki.org/emacs/BzrForEmacsDevs}.

@item Subscribing to the development mailing list

GNU PDF developers communicate using the @email{pdf-devel@@gnu.org}
mailing list. Most of the work in the development is discussed there,
so you definitely want to subscribe to it if you are going to write
some code.

Goto the pdf-devel mailman web interface in
@url{http://lists.gnu.org/mailman/listinfo/pdf-devel} and set up your
subscription. Then, send a first email introducing yourself.

There is another mailing list @email{pdf-tasks@@gnu.org} that is used
by the Flyspray installation to send change notifications of tasks.
You can subscribe to this mailing list at
@url{http://lists.gnu.org/mailman/listinfo/pdf-tasks}.

@item Getting familiar with Savannah

Savannah is the central point of development for GNU software. The GNU
PDF project has a savannah project in
@url{http://savannah.gnu.org/projects/pdf}

@item Getting familiar with the library

Take a look to the design of the library and the source code.  The
documents to look at are the ``GNU PDF Library Reference Guide''
(available in doc/gnupdf.texi) and the ``GNU PDF Library Architecture
Manual'' (available in doc/gnupdf-arch.texi).

If you have doubts about any aspect of the library or the
implementation, just ask in pdf-devel.

@item Getting familiar with the GNU standards

The GNU PDF Library is a GNU package. That means we should follow the
GNU Standards to ensure quality and compatibility with other parts of
the GNU Operating System.

You should be familiar with the GNU Coding Standards before to write
code for the GNU PDF library. You can read it online in
@url{http://www.gnu.org/prep/standards}.

@item Getting familiar with our coding conventions

Read our Hackers Guide (this very document) for several conventions we
use when writing source code.

@item Taking a task to work on

Please read the documentation on tasks management in 
@ref{Tasks management}.

If you want to work in a NEXT task, please be sure to state your
interest in the pdf-devel mailing list before. The developers in the
pdf-devel mailing list can guide you towards the more convenient task
for you to take and can give valuable advice about how to implement
it.

@item Signing papers

The GNU PDF codebase is copyrighted by the Free Software
Foundation. This is a way to strength the GPL. That means that we need
you to sign papers before to be able to integrate your code in the
distribution. There are several ways to get this done. Please ask in
pdf-devel for the details.

@item Sending patches for inclusion

If you have written a patch you want to be included in GNU PDF, please
send it to the pdf-devel mailing list. Your patch will be then
discussed and maybe accepted.

@end table


@node The build system
@chapter The build system

The build system of the GNU PDF software uses the GNU build utilities
(otherwise known as the GNU Autotools). This chapter contains some
guidelines to apply when incorporating changes into the codebase.

@menu
* Third-party m4 macros::
@end menu

@node Third-party m4 macros
@section Third-party m4 macros

Sometimes it is useful to use third-party m4 macros provided by some
build dependency (such as libgcrypt that provides an
@code{AM_PATH_LIBGCRYPT} macro).

In that situation we are introducing a dependency in @emph{bootstrap}
time, and it is not desirable: the dependencies should be checked in
@emph{configure} time.

Any third-party m4 file should be copied in @file{libgnupdf/m4/} and
put under version control. In that way we avoid the dependency in
@emph{bootstrap} time.

@node Development procedures
@chapter Development procedures

The GNU PDF Library is composed by several layers. Each layer is in
turn composed by several modules. The combination of the modules
provide the functionality to layers. @xref{Top,,,gnupdf-arch,}.

The development of the library involves the design of the overall
architecture (determination of the layers that composes the library),
the development of each layer and the design and implementation of
system tests.

@float Figure,fig:lib-development-procedure
@image{gnupdf-hg-figures/lib-development-procedure}
@caption{Library Development Procedure}
@end float

The development of each library layer involves the design of the
overall architecture of the layer (determination of the modules that
composes the layer), the development of each module and the design and
implementation of subsystem tests.

@float Figure,fig:layer-development-procedure
@image{gnupdf-hg-figures/layer-development-procedure}
@caption{Layer Development Procedure}
@end float

The development of each module involves the design of the API offered
by the module and the architectural details, the definition of
development tasks needed to complete the implementation of the module
and the design and implementation of unit tests.

@float Figure,fig:module-development-procedure
@image{gnupdf-hg-figures/module-development-procedure}
@caption{Module Development Procedure}
@end float

@node Tasks management
@chapter Tasks management

This chapter contains information about the tasks management we use in
the development of the GNU PDF Library.

@menu
* The tasks pool::
* Task originators::
* Task types::
* Tasks workflow::
* The flyspray task manager::
@end menu

@node The tasks pool
@section The tasks pool

The real tasks being worked out in the project are contained in what
we call the tasks pool.

The tasks pool contain a set of tasks that should be performed out by
some agent. The pool do not contain all the tasks for the project:
there is an approximation in the project plan. Instead there is a
constant flow of tasks being introduced in the pool by originators and
being consumed out by the developers. That means that when a task is
performed by a developer it is pulled out of the pool and archived.

An archived task can be reactivated and inserted again in the tasks
pool.

@float Figure,fig:tasks-pool
@image{gnupdf-hg-figures/tasks-pool}
@caption{The tasks pool}
@end float

A task is attributed with a priority while it is into the tasks
pool. The priority is a number between 1 (less priority) to 9 (higher
priority). Some priority levels have names:

@itemize @bullet
@item 1 - Later
@item 2
@item 3 - Low
@item 4
@item 5 - Normal
@item 6
@item 7 - High
@item 8
@item 9 - Immediate
@end itemize

@quotation Note
The maintainer may change the priority of a task to avoid it
to starve.
@end quotation

@quotation Note
A reactivated task gets a new priority number when it is
reinserted into the tasks pool.
@end quotation

@node Task originators
@section Task originators

There are several possible originators of tasks:

@table @strong
@item The maintainer
The maintainer is the responsible of maintaining the tasks pool,
introducing new tasks when needed and setting the priorities. The
source of the tasks is either the project plan, bug reports or
reactivated tasks.
@item Cron jobs running in gnupdf.org
There are several cron jobs running in gnupdf.org that perform checks
on a nightly build of the sources and executes the unit tests. These
jobs can automatically generate new tasks to fix some problem (a high
cyclomatic complexity in a module or a fail in a test case).
@end table

@node Task types
@section Task types

We distinguish between some types of tasks. Each task type has an
initial priority defined:

@multitable @columnfractions .25 .25 .25 .25
@headitem task type @tab originator @tab source @tab initial priority
@item @strong{planned task}
@tab maintainer
@tab project plan
@tab 5 (Normal)
@item @strong{sporadic task}
@tab maintainer
@tab bug report
@tab 4
@item @strong{automatic task}
@tab gnupdf.org
@tab test fail or bad software metric
@tab 6
@end multitable

@node Tasks workflow
@section Tasks workflow

The following diagram depicts the possible states for a task and the
allowed transitions between states:

@float Figure,fig:tasks-workflow
@image{gnupdf-hg-figures/tasks-workflow}
@caption{Tasks workflow}
@end float

@table @strong
@item TODO
The task is into the tasks pool but it not ready to be performed.
@item NEXT
The task is into the tasks pool and it is ready to be performed by a
developer.
@item STARTED
The task has been started by a developer but it is not finished.
@item DONE
The task is archived and succesfully performed. 
@item DISCARDED
The task is archived but it has been discarded.
@end table

Note that a task may also be assigned to someone or unassigned:

@table @strong
@item TODO and unassigned
Dependency issues, no one in charge.
@item TODO and assigned
Dependency issues and someone showed interest.
@item NEXT and unassigned
Can be started, nobody interested.
@item NEXT and assigned
Someone is interested but can't work on it for personal issues.
@item STARTED and assigned
Someone is working on the task (no matter the time it takes)
@end table

@node The flyspray task manager
@section The flyspray task manager

We use a flyspray task tracker installed in
@url{http://gnupdf.org/flyspray} in order to implement the tasks pool.

Each flyspray task has the following attributes:

@table @strong
@item Type
The type of the task:
@itemize @minus
@item planned
@item sporadic
@item automatic
@end itemize
@item Category
he context of the task. It may be the name of a library layer (such as
base layer), the name of a library module or a more general context
(such as build system).
@item Priority
The priority of the task. 
@item Status
The status of the task:
@itemize @minus
@item TODO
@item NEXT
@item STARTED
@item DONE
@item DISCARDED.
@end itemize
@item Summary
A summary of the task.
@end table

@node Coding Conventions
@chapter Coding Conventions

Like in any other GNU package, the code in the GNU PDF Library follows
the coding conventions documented in the GNU Coding Standards. 

In this section we complement the guidelines of the GHM with some
specific conventions that we follow in the development of the
library. It is quite important to follow these guidelines to maintain
a good level of coherence in the codebase.

@menu
* File Headers::
* Inclusion of Header Files::
* Testing for Preprocessor Symbols::
* Spaces vs. Tabs::
* Naming Functions::
* Abstract Data Types::
* The layer header files::
@end menu

@node File Headers
@section File Headers

The standard file header to be used in any source file in the library
is the following:

@example
/* -*- mode: C -*-
 *
 *       File:         FILE_NAME
 *       Date:         CREATION_TIME
 *
 *       GNU PDF Project - SHORT_DESCRIPTION
 *
 */
@end example

The entries in the template are:

@table @var
@item FILE_NAME
The basename of the file.
@item CREATION_TIME
A time stamp string in the format:
@example
Fri Feb 22 21:05:05 2008
@end example
Note that if you are writing your code using Emacs then you will get
the appropriate creation date running the @code{current-time-string}
elisp command. If you are using the @code{gnupdf-c-file-header}
skeleton template then you will get the creation date in
template-expansion time.
@item SHORT_DESCRIPTION
A one-sentence brief description of the contents of the file. This
description should not exceed one physical line of text.
@end table

@node Inclusion of Header Files
@section Inclusion of Header Files

The order of the @code{#include} directives in any @file{.c} file
shall be:

@example
/*
 * ... file header ...
 */

#include <config.h>

#include <system-file-1.h>
#include <system-file-2.h>
...
#include <system-file-N.h>

#include <lib-file-1.h>
#include <lib-file-2.h>
...
#include <lib-file-N.h>
@end example

Note the empty lines separating the several blocks.

In particular:

@itemize @minus
@item Always include @file{config.h}, and do it in the first position.
@item Never use the @code{"foo.h"} kind of inclusion.  Use always @code{<foo.h>}.
@end itemize

If some headers shall be included conditionally depending on the host
platform, the macros @code{PDF_HOST_*} defined in @file{config.h} can
be used.  Those macros are set using autoheader.

@node Testing for Preprocessor Symbols
@section Testing for Preprocessor Symbols

Please don't use parentheses like this while testing for pre-processor
symbols:

@example
#if defined (FOO) && defined (BAR) || !defined (BAZ)
  do something
#endif
@end example

Instead, write something like:

@example
#if defined FOO && defined BAR || !defined BAZ
  do something
#endif
@end example

@node Spaces vs. Tabs
@section Spaces vs. Tabs

It is preferable to use blank characters instead of tabs to indent the
source code: the interpretation of the actual width of a tab is up to
the viewer program.

Please use blank characters when writing code to be included in GNU
PDF software. 

If you use Emacs you can tell it to insert spaces instead of tabs
including:

@example
(setq-default indent-tabs-mode nil)
@end example

in your @file{.emacs}.

If you use GNU indent to indent your sources you can use the
@code{--nut} option:

@example
$ indent --nut [rest-of-parameters] [source-files]
@end example

@node Naming Functions
@section Naming Functions

@menu
* Public functions in a module::
* Private functions in a module::
* Platform specific functions::
@end menu

@node Public functions in a module
@subsection Public functions in a module

All the public functions inside a module should use the following name
convention:

@example
pdf_MODULE-NAME_...
@end example

where @var{module-name} is the canonical name of the module
(e.g. @code{alloc} or @code{text}).

Some modules are composed by more than one compilation unit. In that
case the public functions should follow the following name convention:

@example
pdf_MODULE-NAME_PART-NAME_...
@end example

where @var{part-name} is the canonical name of that part of the module
implementation (e.g. @code{pdf_stm_filter_...} where @code{filter} is
the part name.

@node Private functions in a module
@subsection Private functions in a module

The private (``static'') functions used in a module implementation
should follow the same naming conventions as the public ones.

@node Platform specific functions
@subsection Platform specific functions

The names for functions (both public and private) intended to be used
if compiling for a specific platform should use the following name
convention:

@example
pdf_MODULE-NAME[_PART-NAME]_PLATFORM_...
@end example

where @code{platform} is the canonical name for the target platform:

@table @code
@item gnu
For GNU systems.
@item posix
For POSIX systems.
@item win32
For Windows systems.
@item macos
For Macos X systems.
@end table

@node Abstract Data Types
@section Abstract Data Types

The GNU PDF Library codebase is written using the C programming
language. C does not support the notion of @emph{object} as used in
object-oriented programming. 

Instead of objects we are using a kind of data-control abstraction
called @emph{abstract data types}. This abstraction provides high
encapsulation of the implementation details of the data types and thus
allow the definition of @emph{opaque} types.

An ADT is composed by:

@itemize @bullet
@item
A @emph{data structure} containing the private data that characterizes
each instance of the ADT.
@item
A set of @emph{access functions} that implement actions on the
ADT.
@end itemize

@menu
* Implementation Files For ADTs::
* Data Structures For ADTs::
* Access Functions For ADTs::
* Opaque Pointers::
@end menu

@node Implementation Files For ADTs
@subsection Implementation Files For ADTs

Each Abstract Data Type shall be implemented in source files following
this naming convention:

@example
pdf-FOO-*.[ch]
@end example

where @var{FOO} is the name of the ADT; for example,
@file{pdf-text-context.c}.

A general header file for the ADT should always be present
and should be named after:

@example
pdf-FOO.h
@end example

where @var{FOO} is again the name of the ADT; for example,
@file{pdf-text.h}.

@node Data Structures For ADTs
@subsection Data Structures For ADTs

There are two different approaches that shall be used to define the
data structures containing the private data for an ADT:

@table @strong
@item A pointer to a structure
In this case a C structure should be defined to hold the private data:
@example
/* Definition of the pdf_foo_t ADT */
struct pdf_foo_s
@{
   int data_a;
   int data_b;
@};
@end example
and then a typedef that defines @code{pdf_foo_t} as a pointer to that
structure:
@example
typedef struct pdf_foo_s *pdf_foo_t;
@end example
@item A structure
In this case a C structure (not a pointer to it) is used to represent
the ADT:
@example
typedef struct pdf_foo_s pdf_foo_t;
@end example
This alternative is indicated in the case where the private data of
the ADT is small, allowing the developer to allocate
instances of the ADT in the stack and thus avoiding
fragmentation of the heap.
@end table

Note that both alternatives allow to copy a @strong{reference} using
the C assignation operator, like in:

@example
reference_to_adt_instance1 = adt_instance1;
@end example

@node Access Functions For ADTs
@subsection Access Functions For ADTs

Every access function implemented by an ADT should have a
prototype conformant to the following convention:

@example
RETURN_TYPE pdf_FOO_* (pdf_FOO_t adt, args...)
@end example

where @var{FOO} is the name of the ADT.

The following standard functions shall be defined:

@table @code
@item pdf_status_t pdf_FOO_new (args..., pdf_FOO_t *adt)
This is the function used to create a new instance of the
ADT. The last parameter of the function should be a pointer
to a @code{pdf_FOO_t} value. The returned status value should indicate
the state of the operation.
@item pdf_FOO_destroy (pdf_FOO_t adt)
This is the function used to destroy an instance of the
ADT. The memory occupied by the ADT data structure
is freed.
@end table

@node Opaque Pointers
@subsection Opaque Pointers

One way to achieve high encapsulation for ADTs is to publish
``opaque pointers'' in the public header files. The usage of opaque
pointers also improves binary compatibility.  @footnote{this technique
is also known as the PIMPL idiom. See
@url{http://en.wikipedia.org/wiki/Pimpl_idiom}}.

The mechanism is quite simple. Suppose that we want to publish an
opaque ADT to the user: @code{pdf_foo_t}. A first approximation would
be to mark the full definition of @code{pdf_foo_t} as public in the
header file, like:

@example
/* -*- mode: C -*-
 *
 *       File:         pdf-foo.h
 ...
 */

...

/* BEGIN PUBLIC */

struct pdf_foo_s 
@{
   int a;
   int b;
@};

typedef struct pdf_foo_s *pdf_foo_t;

/* END PUBLIC */

...
@end example

Despite the user is not supposed to access the internal structure of
@code{pdf_foo_t}, she @strong{can} actually do it using the exported
structure @code{struct pdf_foo_s}.

An additional problem is that the user can allocate @code{pdf_foo_s}
structs in the stack, and thus the binary compatibility would be break
if the binary links with a more recent version of the library
exporting more fields (like a third integer @code{c}).

The solution to both problems is to export a ``opaque pointer'': we
simply do not export the details about the structure:

@example
/* -*- mode: C -*-
 *
 *       File:         pdf-foo.h
 ...
 */

...

/* BEGIN PUBLIC */

typedef struct pdf_foo_s *pdf_foo_t;

/* END PUBLIC */

struct pdf_foo_s 
@{
   int a;
   int b;
@};

...
@end example

@node The layer header files
@section The layer header files

Each layer in the library provides a header file that gathers the
public headers of its modules.  The header is named after the layer.
@code{pdf-LAYER.h} would contain:

@example
#include <pdf-MODULE1.h>
#include <pdf-MODULE2.h>
...
@end example

@code{pdf-MODULEn.h} being the header files of the modules composing
the layer having @code{BEGIN_PUBLIC}, @code{END_PUBLIC} sections.

The rules regarding those header files are:

@itemize @minus
@item Never use @code{pdf-LAYER.h} in a module of the same layer.
@item Always use @code{pdf-LAYER.h} in modules of another layer.
@end itemize

The second rule avoids the propagation of problems when we make
changes in the module structure of a given layer.  As long as it is
stated that the object layer provides @code{pdf_obj_t}, for example,
it does not matter which specific module provides it.

For example, if we wanted to use the tokeniser @code{pdf_token_read_t}
in the object layer, we would include @code{pdf-base.h} instead of
@code{pdf-token-read.h}.

@node Writing Documentation
@chapter Writing Documentation

This chapter contains some useful information on writing documentation
in the GNU PDF project.

@menu
* Generating pictures with ditaa::
@end menu

@node Generating pictures with ditaa
@section Generating pictures with ditaa

When generating pictures with ditaa, please make sure to not use
implicit shape separation (@command{-E}) nor shadows (@command{-S}).

So, for example:

@example
$ ditaa -S -E [YOUR-OPTIONS] figure.txt
@end example

Don't forget to regenerate both @file{png} and @file{eps} image files
after an update to a picture.

@node Sending Patches
@chapter Sending Patches

This chapter contains some useful information to send patches to be
integrated in the trunk.

@menu
* Documenting Your Changes::
* Generating a Bazaar Merge Directive::
* Syntax Check::
* Patch Safety Dispatcher::
* Sending your Patch::
@end menu

@node Documenting Your Changes
@section Documenting Your Changes

Everyone loves writing documentation! :D

Please update the dates in the copyright notices in each of the files
you have modified, if needed.

Please update the file ChangeLog with a summary of which files have
been changed, along with what the changes were for.

If your change includes new files please update the
@file{MANIFEST.wiki} in the directory containing the new files.

If your change is not trivial please take a look to the appropriate
architecture page in the wiki. Maybe it is needed to update the page
with more information?

@node Generating a Bazaar Merge Directive
@section Generating a Bazaar Merge Directive

The Bazaar version control system supports the notion of @emph{merge
directives}. A merge directive is a kind of ``superpatch'' that contain
an ascii-encoded binary block describing the patch (changes to file
contents, addition of new files, etc) and a preview that is much like
a regular diff.

A merge directive can be merged into a given branch much like any
other branch.

To create a merge directive out of your bazaar branch just type the
following command:

@example
$ bzr send -o my-patch
@end example

Then send the file @file{my-patch} in an email to
@email{pdf-devel@@gnu.org} in order to be reviewed by the development
team.

Note that you dont need to specify extra parameters to the @code{bzr
send} command: it will use the appropriate format for the patch by
default (unidiff).

@node Syntax Check
@section Syntax Check

The maintainer-makefile gnulib module provides some more make targets,
useful for the maintainership of the package.

One of the targets is 'syntax-check'. It performs a check of common
pitfalls on the source code and GCS conformance.

Please do a make syntax-check before to send a patch, or alternatively
use the Patch Safety Dispatcher (see the next section).

Additionally, if you created more tests under 'torture/', please make
sure the new test headers are correct by running:

@example
$ perl ../build-aux/generate-tsd.pl | grep "BAD FORMAT"
@end example

If the @code{BAD FORMAT} mark appears in the output it means that some
of the headers were not properly processed by the
@file{generate-tsd.pl} script.

@menu
* Skipping syntax tests::       Avoid passing tests in some files       
@end menu

@node Skipping syntax tests
@subsection Skipping syntax tests

Sometimes it is not desirable to run an specific test in an specific
source file.  Some typical situations are:

@itemize @minus
@item A false positive of the test.
@item A positive on code that we are not maintaining (for example, any source file in the @file{lib/} directory).
@end itemize

In order to disable the execution of a syntax check in an specific
file, the name of the source file should be added to the file
@file{.x-RULE}, where @file{RULE} is the name of the syntax check.  An
example is the file @file{.x-sc_avoid_if_before_free}, that affects
the syntax check implemented in
@file{build-aux/sc_avoid_if_before_free}.

Note that the @file{.x-RULE} files should not contain empty lines.

In order to disable the execution of a syntax check for any file, just
add the name of the syntax check to the @code{local-checks-to-skip}
variable in @file{cfg.mk}.

@node Patch Safety Dispatcher
@section Patch Safety Dispatcher

Before sending a patch to the list to be included in the trunk you
can run the patch safety dispatcher, which is a script that runs a
few more scripts, like the syntax check mentioned in this chapter.

In fact, the Patch Safety Dispatcher is a bzr plugin that is run before a
commit is applied to your working copy.
In order to execute it you need to tell bzr where the plugin is
located. There are two ways to do it:

1. Copy the script located in ``prmgt/patch-safety-dispatcher.py'' at
the projects root directory to your bazaar plugins directory
``~/.bazaar/plugins''.

2. Add the ``prmgt'' directory to the BZR_PLUGIN_PATH variable. For
example, doing ``export BZR_PLUGIN_PATH=/your/path/to/libgnupdf/prmgt''
(alternatively you can add it to your ~/.bashrc).

After telling bzr where your plugins are, you can test it doing: ``bzr
hooks'' (from the projects root directory) . You should find it in the
list as ``Patch safety scripts hook'' in the pre_commit section.

That's all. Now when you do a ``bzr commit'' a small report will tell if
your patch is correct in terms of the QA scripts we run daily.
If it is the commit will be applied, otherwise it won't.

Note that the current hook only works with Bazaar 1.5 or later. To
make it work on the older bazaar, you just need to replace this line:

@example
branch.Branch.hooks.install_named_hook('pre_commit', pre_commit_hook,
                                'Patch safety scripts hook')
@end example

with these lines:

@example
branch.Branch.hooks.install_hook('pre_commit', pre_commit_hook)
branch.Branch.hooks.name_hook(pre_commit_hook, 'Patch safety scripts hook')
@end example

NOTE: Make sure you run ``bzr commit'' from your working copy root
directory.  Bazaar will fail with some error or don't even run the
script otherwise. Until now we have no solution for this problem.

@node Sending your Patch
@section Sending your Patch

Before to send the patch to be considered for merging, please use the
following checkpoints list to make sure that everything is in place:

@itemize @minus
@item Is the patch including a ChangeLog entry?
@item Is the patch including an update to the @code{AUTHORS} file documenting any new modified/created file by you?
@item What about the copyright headers?  Did you copy the header from other file and therefore it is needed to change the copyright years?
@end itemize

If everything is ok please send the patch to
@email{pdf-devel@@gnu.org}.  Note that it is preferable to include the
merge directive in the message body than to send it as an attachment.

@node Testing the library
@chapter Testing the library

We are following a bottom-up testing strategy. The verification of the
library is performed in the following steps:

@float Figure,fig:test-types
@image{gnupdf-hg-figures/test-types}
@caption{Test types}
@end float

@enumerate
@item @strong{Unit testing} is performed in order to verify the low-level modules of the library.
@item @strong{Subsystem testing} is performed in order to verify the combination of several subsystems. i.e. to test each library layer.
@item @strong{System testing} is performed in order to verify the whole system. i.e. the GNU PDF Library. 
@end enumerate

We use check @footnote{A testing framework for C. See http://check.sf.net} 
to implement our testing infrastructure. Please
read the check manual in order to become familiar with its concepts
such as test suite, test case, etc.

At some point we wrote a simple replacement for libcheck in Windows
systems: nocheck (@file{torture/unit/nocheck}).  The usage of the
replacement is now deprecated, since the latest version of libcheck
should support windows.

@menu
* The test specification document::
* Unit testing::
* Test Data Files::
* The tortutils Library::
@end menu

@node The test specification document
@section The test specification document

The tests for the GNU PDF Library are documented in a document called
"Test Specification Document" or TSD. It is available as a texinfo
file in the sources distribution in the @file{doc/gnupdf-tsd.texi}
file.

There is an online version of the TSD in
@url{http://www.gnupdf.org/manuals/gnupdf-tsd.html}. It is
automatically updated daily from the bazaar trunk.

@node Unit testing
@section Unit testing

We organize unit tests using the following structure:

@float Figure,fig:unit-testing-architecture
@image{gnupdf-hg-figures/unit-testing-architecture}
@caption{Unit Testing Architecture}
@end float

Test suites are used to collect unit tests for a given module. In turn
each test suite contain a collection of test cases. Each test case
identifies a function implemented in the module. Several tests can
then be defined to test the function capabilities.

The unit tests are stored in the @file{torture/unit/} directory.

@float Figure,fig:unit-testing-sources
@image{gnupdf-hg-figures/unit-testing-sources}
@caption{Unit Testing Sources}
@end float

@menu
* Designing unit tests::
* Test files::
* Test suite files::
* The runtests program::
* Running the unit tests::
* Using gdb to debug check tests::
@end menu

@node Designing unit tests
@subsection Designing unit tests

Please keep in mind the following considerations when designing unit
tests for the functions of a library module:

For any given function we would like to define @strong{positive},
@strong{negative} and @strong{stressing} unit tests:

@itemize @minus
@item @strong{Positive tests} are used to test the function with valid input data. The return value (or any documented side effect) of the function should be checked with the expected effect.
@item @strong{Negative tests} are used to test the function with invalid input data.
@item @strong{Stressing tests} are used to test the function with strategic or "interesting" valid input data (such as @code{MAXINT} or @code{MININT} in a function accepting an integer value). 
@end itemize

Many functions are simple enough to only require a single positive
test running the function (no parameters). It is important to have
this unit test since the execution may fail even for such simple
functions.

While designing the unit tests you may find that the API contain
errors or that it may be improved in any way. That is fine and it is
quite welcomed. You can propose any change of the API in this list.

@node Test files
@subsection Test files

The test files contain collections of unit tests associated with a
function. Each test file is named @file{function-name.c}, where
@file{function-name} is the name of the function under testing with
underscores replaced with dashes.

For example, the source file containing unit tests for the pdf_stm_new
function would be called @file{stm-new.c}.

A minimal test file looks like this:

@example
/* 
 * Include the check library.
 */
#include <check.h>

/* 
 * Test: FUNCTION_NAME_NNN
 * Description:
 *   Description of the test.  Can be of several lines long,
 *   indenting the text like this.
 * Success conditions:
 *   A list of success conditions.
 * Data files:
 *   A list of data files used in this test.
 */
START_TEST(FUNCTION_NAME_NNN)
@{
  /* Check a condition.  One of several types of check 
     available in the check library.
   */
  fail_if(0 == 1);
@}
END_TEST


/* 
 * Provide this function to gather all the tests together.
 */
TCase* test_FUNCTION_NAME (void)
@{
  TCase* tc = tcase_create ("FUNCTION_NAME");
  tcase_add_test(tc, FUNCTION_NAME_NNN);
  return tc;
@}
@end example

Note the @code{test_FUNCTION_NAME} function. It is the function called
by the test driver in order to perform all the tests implemented in
the test file.

Note also that the comments heading tests are written in a fixed
format to allow the @file{build-aux/generate-tsd.pl} script to
generate the bulk of the Test Specification Document from the
comments.

@node Test suite files
@subsection Test suite files

Once you add a new test file, that defines a testcase for some module
function, you need to integrate it into the test suite that defines
the module itself.

Each module directory (such as @file{torture/unit/base/stm}) has a
test suite definition file such as @file{tsuite-stm.c}. The suite
definition file defines a function called @file{tsuite_MODULE-NAME}
that return a @code{Suite *} object.

New test cases are added using the @code{suite_add_tcase} function:

@example
extern TCase *my_new_tcase (void);

Suite *
tsuite_mymodule ()
@{
  Suite *s;
  ...

  suite_add_tcase (s, my_new_tcase ());
  ...

  return s;
@}
@end example

@node The runtests program
@subsection The runtests program

The runtests program is the driver of the testing procedure. It is
located in the @file{torture/unit/} directory.

In order to integrate new test files into the runtests program the
source files of the test files should be added to the value of the
@code{TEST_FILES} variable in @file{torture/unit/Makefile.am}.

For example:

@example
TEST_FILES = base/stm/pdf-create-file-stm.c \
             base/OTHER-MODULE/OTHER-TEST-FILE.c
@end example

@node Running the unit tests
@subsection Running the unit tests

The runtests program will run all the defined unit tests of the
library. It can be invoked (and it is the preferred way) by executing:

@example
$ make check
@end example

It is possible to run the unit tests corresponding to a specific
library module by using the @command{MODULE} variable:

@example
$ make check MODULE=fsys
@end example

It is also possible to run the unit tests corresponding to a specific
public function by using the @command{FUNCTION} variable:

@example
$ make check FUNCTION=fsys_close_file
@end example

The test driver display several messages to the standard output and
also dump a logfile named @file{ut.log} with details about the test
execution.

The runtests program will (by default) output a list of which test
suites were run, then a summary line followed by a list of failing
lists. You can get a full list of tests (passing and failing) by 
setting the @code{CK_VERBOSITY} environment variable to 'verbose'.
You can get just the summary line and failing lists by setting the
@code{CK_VERBOSITY} environment variable to 'minimal', and you can
produce no output by setting it to 'silent'. Note that tests (in
particular, the error reporting tests) may output additional 
information as part of their normal operation - that isn't really
part of the check testing framework, and won't be affected by the
@code{CK_VERBOSITY} environment variable.

If the library was cross compiled in a GNU system using mingw32,
@command{make check} will try to invoke @command{wine} to execute the
@file{runtests.exe} binary.  If the compilation was performed in a
native windows environment then @file{runtests.exe} will be used
directly.

@node Using gdb to debug check tests
@subsection Using gdb to debug check tests

The check testing framework uses fork calls in order to create the
processes used to run the single tests. This makes possible to catch
unexpected process terminations such as a segmentation fault or a
division by zero.

Sometimes we want to debug those failure conditions using
gdb. Unfortunately the GNU debugger cannot catch the unexpected
termination of the child processess.

The check implementor foresaw this and provides a workaround: to
define the @code{CK_FORK} environment variable to "no" and launch
the debugger.

The test driver @file{torture/unit/runtests} is a shell script
generated by libtool. This means that it is not possible to run it
invoking gdb from the command line, as in:

@example
$ gdb torture/unit/runtests
@end example

A solution for this problem is to edit the
@file{torture/unit/runtests} and hack it so it will call gdb instead
of the program in @file{.libs/}. Just find the line containing
something like:

@example
exec "$progdir/$program" $@{1+"$@@"@}
@end example

and change it to something like:

@example
exec gdb --return-child-result --quiet --args "$progdir/$program" $@{1+"$@@"@}
@end example

Note that you need to repeat this change every time
@file{torture/unit/runtests} is rebuilt by @command{make}.

The second alternative is to run gdb on the real binary using:

@example
$ LD_LIBRARY_PATH=/path/to/libgnupdf/src/.libs:$LD_LIBRARY_PATH gdb torture/unit/.libs/runtests
@end example

When debugging failing tests you may find it useful to set breakpoint
to @code{_fail_unless} function:

@example
$ @strong{( export CK_FORK='no'; make check )}   # you can use 'make check FUNCTION=...' as well
...
(gdb) @strong{break _fail_unless}
Breakpoint 1 at 0x804ac44
(gdb) @strong{run}
...
Breakpoint 1, _fail_unless (result=1, file=0x80b2f94 "base/alloc/pdf-alloc.c",
    line=47, expr=0x80aac30 "Failure 'data == NULL' occured") at check.c:237
237       send_loc_info (file, line);
...
(gdb) @strong{list}
232     void _fail_unless (int result, const char *file,
233                        int line, const char *expr, ...)
234     @{
235       const char *msg;
236
237       send_loc_info (file, line);
@strong{238       if (!result) @{}
239         va_list ap;
240         char buf[BUFSIZ];
241
(gdb) @strong{break check.c:238 if (!result)}
Breakpoint 2 at 0xb7ea4a7c: file check.c, line 238.
(gdb) @strong{delete 1}
(gdb) @strong{continue}
Continuing.
...
Breakpoint 2, _fail_unless (result=0,
    file=0x80a7ef8 "base/text/pdf-text-new-destroy.c", line=44,
    expr=0x80a7f1c "Assertion 'pdf_text_new (&newtext) == PDF_EBADCONTEXT' failed")
    at check.c:238
238       if (!result) @{
(gdb) @strong{finish}
Run till exit from #0  _fail_unless (result=0,
    file=0x80a7ef8 "base/text/pdf-text-new-destroy.c", line=44,
    expr=0x80a7f1c "Assertion 'pdf_text_new (&newtext) == PDF_EBADCONTEXT' failed")
    at check.c:238
pdf_text_new_destroy_001 (_i=0) at base/text/pdf-text-new-destroy.c:46
46      END_TEST
(gdb) @strong{list}
41      @{
42        pdf_text_t newtext = NULL;
43
44        fail_unless(pdf_text_new (&newtext) == PDF_EBADCONTEXT);
45      @}
46      END_TEST
47
48      /*
49       * Test: pdf_text_new_destroy_002
50       * Description:
(gdb) ...
@end example

@node Test Data Files
@section Test Data Files

Some tests require the use of data files:

@itemize @minus
@item to hold input for the software under test
@item to hold output to be compared with the output of the software under test
@end itemize

The test data files are distributed in the @file{torture/testdata}
directory along with the source code.

The test data files are documented in the ``Test Data Files'' chapter
in the Test Specification Document.

@node The tortutils Library
@section The tortutils Library

The ``torture utils'' library provides several utility functions that
can be used while writing tests.

See @file{torture/tortutils/tortutils.h} for documentation on the
functions provided by the library.

@node Updating the AUTHORS file
@chapter Updating the AUTHORS file

The @file{AUTHORS} file is automatically generated using Emacs.  The
@file{prmgt/authors.el} elisp file contains the implementation of the
@code{author} function.

In order to regenerate the file:

@enumerate
@item Launch Emacs
@item Load the @file{prmgt/authors.el} file.
@item Call @kbd{M-xauthors} and specify the libgnupdf source tree.
@item Update AUTHORS with the contents of the @code{*Authors*} buffer.
@end enumerate

@bye
